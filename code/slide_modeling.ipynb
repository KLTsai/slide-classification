{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from docarray import dataclass, Document, DocumentArray\n",
    "from docarray.typing import Image, Text, JSON, URI\n",
    "import ast\n",
    "import pandas as pd\n",
    "import os\n",
    "import platform\n",
    "import shutil\n",
    "\n",
    "is_windows = platform.system().lower() == 'windows'\n",
    "if is_windows:\n",
    "    source_dir = \"C:\\\\Users\\\\Kun\\\\Desktop\" \n",
    "else:\n",
    "    source_dir = \"/Users/kun-lin/Desktop\"\n",
    "source_dir = os.path.join(source_dir, f\"Angebot\")\n",
    "dest_dir = \"output\"\n",
    "PPTtoImg_dir = os.path.join(dest_dir, f\"PPTtoImg\")\n",
    "fWordImg_dir = os.path.join(dest_dir, f\"FewWordImg\")\n",
    "ct_fWordImg_dir = os.path.join(fWordImg_dir, f\"CT_FewWordImg\")\n",
    "topshapetype_dir = os.path.join(dest_dir, f\"TopShapeTypeImg\")\n",
    "labels_dir = os.path.join(dest_dir, f\"LABELS\")\n",
    "checkpoint_path = os.path.join(dest_dir, f\"checkpoints\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load alignment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 26468 entries, 0 to 26467\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   file_name   26468 non-null  object\n",
      " 1   page_num    26468 non-null  int64 \n",
      " 2   shape_type  26468 non-null  object\n",
      " 3   contents    26468 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def convert_to_list(data):\n",
    "    return ast.literal_eval(data)\n",
    "# Since it take too much time on traversal ppt files, Easily to import the dataframe from the csv file\n",
    "df_da = pd.read_csv('alignment_pptx_list.csv', converters={'shape_type': convert_to_list})\n",
    "# for Mac OS\n",
    "if not is_windows:\n",
    "    df_da['file_name'] = df_da['file_name'].apply(lambda x: x.replace('C\\\\Users\\\\Kun\\\\Desktop\\\\Angebot', source_dir))\n",
    "    df_da['file_name'] = df_da['file_name'].apply(lambda x: x.replace('\\\\', '/'))\n",
    "\n",
    "df_da = df_da[~df_da['contents'].isnull()]\n",
    "df_da.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 23148 entries, 0 to 26467\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   file_name   23148 non-null  object\n",
      " 1   page_num    23148 non-null  int64 \n",
      " 2   shape_type  23148 non-null  object\n",
      " 3   contents    23148 non-null  object\n",
      " 4   word_count  23148 non-null  int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# filter out less than 4 words\n",
    "df_da['word_count'] = df_da['contents'].apply(lambda x: len(str(x).split()) if pd.notna(x) else 0)\n",
    "df_few_words = df_da[~(df_da['word_count'] <= 4)]\n",
    "df_few_words.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy filtered-slide images to new folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_png_files(directory):\n",
    "    for filename in os.listdir(directory):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        if os.path.isfile(filepath) and filename.lower().endswith(\".PNG\"):\n",
    "            os.remove(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy filtered-data to new folder(FewWordImg)\n",
    "delete_png_files(fWordImg_dir)\n",
    "uni_path = df_few_words['file_name'].unique()\n",
    "\n",
    "for path in uni_path:\n",
    "    for idx, row in df_few_words[df_few_words['file_name'] == path].iterrows():\n",
    "        # print(row['file_name'])\n",
    "        exec_path = os.path.abspath(PPTtoImg_dir)  # image output path\n",
    "        if is_windows:\n",
    "            # for windows OS\n",
    "            ktr = row['file_name'].split('\\\\')[-2]\n",
    "        else:\n",
    "            # for Mac OS\n",
    "            ktr = row['file_name'].split('/')[-2]\n",
    "        name = os.path.basename(row['file_name'])\n",
    "        name = name.split('.')[0]\n",
    "        name = '_'.join([ktr, name, \"%d.PNG\" % row['page_num']])\n",
    "        imgpath = os.path.join(exec_path, name)\n",
    "        \n",
    "        # from PPTtoImg to FewWordImg\n",
    "        shutil.copy(imgpath, os.path.join(os.getcwd(), fWordImg_dir))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This process is to ignore **Chapter Covers** images so that we make them labeling easier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using `docarray` to construct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class MySlide:\n",
    "    Content: Text #chunk\n",
    "    ImgPath: Image #chunk\n",
    "    ShapeType: List[str] #tag\n",
    "    PageNum: int #tag\n",
    "\n",
    "@dataclass\n",
    "class MyPPT:\n",
    "    FileName: Text\n",
    "    Slide: List[MySlide]\n",
    "\n",
    "group_slide = DocumentArray()\n",
    "uni_path = df_few_words['file_name'].unique()\n",
    "\n",
    "for path in uni_path:\n",
    "    for idx, row in df_few_words[df_few_words['file_name'] == path].iterrows():\n",
    "        # print(row['file_name'])\n",
    "        exec_path = os.path.abspath(fWordImg_dir)  # filter-images output path\n",
    "        if is_windows:\n",
    "            # for windows OS\n",
    "            ktr = row['file_name'].split('\\\\')[-2]\n",
    "        else:\n",
    "            # for Mac OS\n",
    "            ktr = row['file_name'].split('/')[-2]\n",
    "        name = os.path.basename(row['file_name'])\n",
    "        name = name.split('.')[0]\n",
    "        name = '_'.join([ktr, name, \"%d.PNG\" % row['page_num']])\n",
    "        imgpath = os.path.join(exec_path, name)\n",
    "        # imgpath = os.path.join(image_dir_path, )\n",
    "        m = MySlide(\n",
    "                    Content = row['contents'],\n",
    "                    ImgPath = imgpath,\n",
    "                    ShapeType = row['shape_type'],\n",
    "                    PageNum = row['page_num'],\n",
    "                )\n",
    "        \n",
    "        group_slide.append(Document(m))\n",
    "            \n",
    "docPPT = Document(MyPPT(FileName = path, Slide = group_slide))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        iCert 20 Change Management  Design Sprint  Sup...\n",
       "1        B  Intranet Create content and setup concept s...\n",
       "2        Contractors Duty to Collaborate UNITY shall as...\n",
       "3        Thematic Focus Transformation change managemen...\n",
       "4        Secure Life Cycle Management LCM Process Enclo...\n",
       "                               ...                        \n",
       "23143    6079 Heinrich Meintrup Executive Vice Presiden...\n",
       "23144    9561 Analysis and critical review of the curre...\n",
       "23145    PPMRail project KnorrBremse is consolidating a...\n",
       "23146    Evaluate the scope of the implemented function...\n",
       "23147    UNITY  Your partner in innovation  transformat...\n",
       "Name: text, Length: 23148, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docPPT.Slide['@.[Content]'].to_dataframe().text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "slide_1200 = docPPT.Slide.sample(1200, 42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline models construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import StratifiedKFold, RepeatedStratifiedKFold, cross_val_score, train_test_split, GridSearchCV\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will print the metrcis for diffeent model\n",
    "def print_model_report(y_test, prediction, ML_modelName):\n",
    "    print(\"Model report for: \"+ ML_modelName + \"\\n\")\n",
    "    print(classification_report(y_test, prediction, digits=4))\n",
    "    \n",
    "    \n",
    "# Show confusion matrix plot\n",
    "def plot_confusion_matrix(y_test, prediction, ML_modelName, cmap):\n",
    "    cm = confusion_matrix(y_test, prediction)\n",
    "    \n",
    "    ax = sns.heatmap(cm, \n",
    "              annot=True, \n",
    "              annot_kws={'size':18,'weight':'normal'},\n",
    "              fmt='.20g', \n",
    "              cmap=cmap, \n",
    "              cbar_kws={'shrink':1},\n",
    "              linewidths=2)\n",
    "    \n",
    "    plt.title(\"Confusion Matrix for: \" + ML_modelName)\n",
    "    plt.ylabel(\"Actual Label\")\n",
    "    plt.xlabel(\"Predict Label\")\n",
    "    cbar = ax.collections[0].colorbar\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def stratifiedVD(X_train, y_train, ex_model):\n",
    "    #StratifiedKFold is a variation of KFold\n",
    "    SKF = StratifiedKFold(n_splits=10, random_state=42, shuffle=True).split(X_train, y_train)\n",
    "    \n",
    "    score_list = []\n",
    "    for k, (train, test) in enumerate(SKF):\n",
    "\n",
    "        print(train.shape, test.shape)\n",
    "        # instantiate the model\n",
    "        ex_model.fit(X_train.iloc[train], y_train.iloc[train])\n",
    "        # calculate the score each fold\n",
    "        score = ex_model.score(X_train.iloc[test], y_train.iloc[test])\n",
    "        score_list.append(score)\n",
    "\n",
    "        print(f'Fold: {k+1:2d}, Class dist.: {np.bincount(y_train.iloc[train])}, Acc: {score:.3f}')    \n",
    "\n",
    "    print(f'\\nCV accuracy: {np.mean(score_list):.3f} +/- {np.std(score_list):.3f}')\n",
    "    \n",
    "\n",
    "def evaluate_model(X, y, pipline):\n",
    "    # instantiate the model\n",
    "    RSKF = RepeatedStratifiedKFold(n_splits=10, random_state=42, n_repeats=3)\n",
    "    scores = cross_val_score(pipline, X, y, cv= RSKF, scoring='accuracy', n_jobs=-1)\n",
    "    return scores\n",
    "\n",
    "\n",
    "def roc_auc_score_multiclass(actual_class, pred_class, average = \"macro\"):\n",
    "    \n",
    "    #creating a set of all the unique classes using the actual class list\n",
    "    unique_class = set(actual_class)\n",
    "    roc_auc_dict = {}\n",
    "    for per_class in unique_class:\n",
    "        \n",
    "        #creating a list of all the classes except the current class \n",
    "        other_class = [x for x in unique_class if x != per_class]\n",
    "\n",
    "        #marking the current class as 1 and all other classes as 0\n",
    "        new_actual_class = [0 if x in other_class else 1 for x in actual_class]\n",
    "        new_pred_class = [0 if x in other_class else 1 for x in pred_class]\n",
    "\n",
    "        #using the sklearn metrics method to calculate the roc_auc_score\n",
    "        # roc_auc = roc_auc_score(new_actual_class, new_pred_class, average = average)\n",
    "        roc_auc = roc_auc_score(new_actual_class, new_pred_class, average= average , multi_class=\"ovr\")\n",
    "\n",
    "        roc_auc_dict[per_class] = roc_auc\n",
    "\n",
    "    return roc_auc_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training set and Testing set spilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_augment = {'ori':docPPT.Slide, 'slide_1200':slide_1200}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ori (23148,) (23148,)\n",
      "slide_1200 (1200,) (1200,)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "categories = [\n",
    "    \"Offer title\", \n",
    "    \"Initial Situation\", \n",
    "    \"Target Situation\", \n",
    "    \"Initial & Target Situation\", \n",
    "    \"Reference Overview\", \n",
    "    \"Reference Details\", \n",
    "    \"Competencies\", \n",
    "    \"Working Package Overview\", \n",
    "    \"Work Package Description\", \n",
    "    \"Working Package Examples\", \n",
    "    \"Consultant Profile\", \n",
    "    \"Project Calculation\"\n",
    "]\n",
    "\n",
    "def get_X_y_set(dict_aug):\n",
    "    dict_ = dict()\n",
    "    for str, da in dict_aug.items():\n",
    "        \n",
    "        X = da['@.[Content]'].to_dataframe().text\n",
    "        y = pd.Series(random.choices(categories, k = len(da['@.[Content]'].to_dataframe().text)))\n",
    "        print(str, X.shape, y.shape)\n",
    "        dict_[str] = pd.DataFrame({'X': X, 'y':y})    \n",
    "        \n",
    "    return dict_\n",
    "\n",
    "dict_X_y = get_X_y_set(dict_augment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Test data splits\n",
    "keys = 'slide_1200'\n",
    "X_train, X_test, y_train, y_test = train_test_split(dict_X_y[keys]['X'], dict_X_y[keys]['y'], test_size=0.3, \n",
    "                                                    stratify=dict_X_y[keys]['y'], random_state=42, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>120</th>\n",
       "      <th>1886</th>\n",
       "      <th>20</th>\n",
       "      <th>2019</th>\n",
       "      <th>2022</th>\n",
       "      <th>20222025</th>\n",
       "      <th>2023</th>\n",
       "      <th>2025</th>\n",
       "      <th>2030</th>\n",
       "      <th>24</th>\n",
       "      <th>...</th>\n",
       "      <th>zügigen</th>\n",
       "      <th>zürich</th>\n",
       "      <th>ärztliche</th>\n",
       "      <th>überführung</th>\n",
       "      <th>übergabe</th>\n",
       "      <th>übergabepunkte</th>\n",
       "      <th>übergreifend</th>\n",
       "      <th>übergreifenden</th>\n",
       "      <th>übernahme</th>\n",
       "      <th>überwachen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>840 rows × 1600 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     120  1886  20  2019  2022  20222025  2023  2025  2030  24  ...  zügigen  \\\n",
       "0      0     0   0     0     0         0     0     0     0   0  ...        0   \n",
       "1      0     0   0     0     0         0     0     0     0   0  ...        0   \n",
       "2      0     0   0     0     0         0     0     0     0   0  ...        0   \n",
       "3      0     0   0     0     0         0     0     0     0   0  ...        0   \n",
       "4      0     0   0     0     0         0     0     0     0   0  ...        1   \n",
       "..   ...   ...  ..   ...   ...       ...   ...   ...   ...  ..  ...      ...   \n",
       "835    0     0   0     0     0         0     0     0     0   0  ...        0   \n",
       "836    0     0   0     0     0         0     0     0     0   0  ...        0   \n",
       "837    0     0   0     0     0         0     0     0     0   0  ...        0   \n",
       "838    0     0   0     0     0         0     0     0     0   0  ...        0   \n",
       "839    0     0   0     0     0         0     0     0     0   0  ...        0   \n",
       "\n",
       "     zürich  ärztliche  überführung  übergabe  übergabepunkte  übergreifend  \\\n",
       "0         0          0            0         0               0             0   \n",
       "1         0          0            0         0               0             0   \n",
       "2         0          0            0         0               0             0   \n",
       "3         0          0            0         0               0             0   \n",
       "4         0          0            0         0               0             0   \n",
       "..      ...        ...          ...       ...             ...           ...   \n",
       "835       0          0            0         0               0             0   \n",
       "836       0          0            0         0               0             0   \n",
       "837       0          0            0         0               0             0   \n",
       "838       0          0            0         0               0             0   \n",
       "839       0          0            0         0               0             0   \n",
       "\n",
       "     übergreifenden  übernahme  überwachen  \n",
       "0                 0          0           0  \n",
       "1                 0          0           0  \n",
       "2                 0          0           0  \n",
       "3                 0          0           0  \n",
       "4                 0          0           0  \n",
       "..              ...        ...         ...  \n",
       "835               0          0           0  \n",
       "836               0          0           0  \n",
       "837               0          0           0  \n",
       "838               0          0           0  \n",
       "839               0          0           0  \n",
       "\n",
       "[840 rows x 1600 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bag of words for chi square\n",
    "vectorize_cal = CountVectorizer(max_df= 0.85, min_df=2)\n",
    "sparse_matrix = vectorize_cal.fit_transform(X_train, y_train)\n",
    "\n",
    "df_bow=pd.DataFrame(sparse_matrix.toarray(), columns=vectorize_cal.get_feature_names_out())\n",
    "\n",
    "k_best_cal = SelectKBest(score_func = chi2, k = 1600)\n",
    "best_matrix = k_best_cal.fit(df_bow, y_train)\n",
    "\n",
    "cols = best_matrix.get_support(indices=True)\n",
    "features_df_new = df_bow.iloc[:,cols]\n",
    "features_df_new"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_nb = Pipeline([('vect', CountVectorizer(max_df=0.85, min_df=2)),\n",
    "                        ('chi', SelectKBest(score_func = chi2, k = 1600)),\n",
    "                        ('tfidf', TfidfTransformer()),\n",
    "                        ('model', MultinomialNB())])\n",
    "\n",
    "\n",
    "model_nb = pipeline_nb.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratifiedVD(X_train, y_train, model_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_nb = model_nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print model report for LogisticRegression\n",
    "print_model_report(y_test, pred_nb, \"Naive Bayes\")\n",
    "# Visualize the Confusion Matrix for LogisticRegression!\n",
    "plot_confusion_matrix(y_test, pred_nb, \"Naive Bayes\", plt.cm.Oranges)\n",
    "roc_auc_score_multiclass(y_test, pred_nb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual-wise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UNITY39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
